{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ! pip install ftfy regex tqdm\n# ! pip install git+https://github.com/openai/CLIP.git","metadata":{"execution":{"iopub.status.busy":"2023-07-29T13:33:35.297504Z","iopub.execute_input":"2023-07-29T13:33:35.297912Z","iopub.status.idle":"2023-07-29T13:33:35.305636Z","shell.execute_reply.started":"2023-07-29T13:33:35.297880Z","shell.execute_reply":"2023-07-29T13:33:35.303037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install open_clip_torch","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:02:09.992153Z","iopub.execute_input":"2023-07-29T17:02:09.992514Z","iopub.status.idle":"2023-07-29T17:02:23.162024Z","shell.execute_reply.started":"2023-07-29T17:02:09.992478Z","shell.execute_reply":"2023-07-29T17:02:23.160602Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting open_clip_torch\n  Downloading open_clip_torch-2.20.0-py3-none-any.whl (1.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.15.1)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (2023.6.3)\nCollecting ftfy (from open_clip_torch)\n  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (4.65.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.16.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.1.99)\nRequirement already satisfied: protobuf<4 in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (3.20.3)\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (from open_clip_torch) (0.9.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->open_clip_torch) (3.1.2)\nRequirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.10/site-packages (from ftfy->open_clip_torch) (0.2.6)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (2023.6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->open_clip_torch) (21.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm->open_clip_torch) (0.3.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->open_clip_torch) (1.23.5)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->open_clip_torch) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->open_clip_torch) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->open_clip_torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->open_clip_torch) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9.0->open_clip_torch) (1.3.0)\nInstalling collected packages: ftfy, open_clip_torch\nSuccessfully installed ftfy-6.1.1 open_clip_torch-2.20.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import open_clip\nopen_clip.list_pretrained()","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:02:23.164864Z","iopub.execute_input":"2023-07-29T17:02:23.165273Z","iopub.status.idle":"2023-07-29T17:02:29.870507Z","shell.execute_reply.started":"2023-07-29T17:02:23.165235Z","shell.execute_reply":"2023-07-29T17:02:29.869549Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"[('RN50', 'openai'),\n ('RN50', 'yfcc15m'),\n ('RN50', 'cc12m'),\n ('RN50-quickgelu', 'openai'),\n ('RN50-quickgelu', 'yfcc15m'),\n ('RN50-quickgelu', 'cc12m'),\n ('RN101', 'openai'),\n ('RN101', 'yfcc15m'),\n ('RN101-quickgelu', 'openai'),\n ('RN101-quickgelu', 'yfcc15m'),\n ('RN50x4', 'openai'),\n ('RN50x16', 'openai'),\n ('RN50x64', 'openai'),\n ('ViT-B-32', 'openai'),\n ('ViT-B-32', 'laion400m_e31'),\n ('ViT-B-32', 'laion400m_e32'),\n ('ViT-B-32', 'laion2b_e16'),\n ('ViT-B-32', 'laion2b_s34b_b79k'),\n ('ViT-B-32', 'datacomp_m_s128m_b4k'),\n ('ViT-B-32', 'commonpool_m_clip_s128m_b4k'),\n ('ViT-B-32', 'commonpool_m_laion_s128m_b4k'),\n ('ViT-B-32', 'commonpool_m_image_s128m_b4k'),\n ('ViT-B-32', 'commonpool_m_text_s128m_b4k'),\n ('ViT-B-32', 'commonpool_m_basic_s128m_b4k'),\n ('ViT-B-32', 'commonpool_m_s128m_b4k'),\n ('ViT-B-32', 'datacomp_s_s13m_b4k'),\n ('ViT-B-32', 'commonpool_s_clip_s13m_b4k'),\n ('ViT-B-32', 'commonpool_s_laion_s13m_b4k'),\n ('ViT-B-32', 'commonpool_s_image_s13m_b4k'),\n ('ViT-B-32', 'commonpool_s_text_s13m_b4k'),\n ('ViT-B-32', 'commonpool_s_basic_s13m_b4k'),\n ('ViT-B-32', 'commonpool_s_s13m_b4k'),\n ('ViT-B-32-quickgelu', 'openai'),\n ('ViT-B-32-quickgelu', 'laion400m_e31'),\n ('ViT-B-32-quickgelu', 'laion400m_e32'),\n ('ViT-B-16', 'openai'),\n ('ViT-B-16', 'laion400m_e31'),\n ('ViT-B-16', 'laion400m_e32'),\n ('ViT-B-16', 'laion2b_s34b_b88k'),\n ('ViT-B-16', 'datacomp_l_s1b_b8k'),\n ('ViT-B-16', 'commonpool_l_clip_s1b_b8k'),\n ('ViT-B-16', 'commonpool_l_laion_s1b_b8k'),\n ('ViT-B-16', 'commonpool_l_image_s1b_b8k'),\n ('ViT-B-16', 'commonpool_l_text_s1b_b8k'),\n ('ViT-B-16', 'commonpool_l_basic_s1b_b8k'),\n ('ViT-B-16', 'commonpool_l_s1b_b8k'),\n ('ViT-B-16-plus-240', 'laion400m_e31'),\n ('ViT-B-16-plus-240', 'laion400m_e32'),\n ('ViT-L-14', 'openai'),\n ('ViT-L-14', 'laion400m_e31'),\n ('ViT-L-14', 'laion400m_e32'),\n ('ViT-L-14', 'laion2b_s32b_b82k'),\n ('ViT-L-14', 'datacomp_xl_s13b_b90k'),\n ('ViT-L-14', 'commonpool_xl_clip_s13b_b90k'),\n ('ViT-L-14', 'commonpool_xl_laion_s13b_b90k'),\n ('ViT-L-14', 'commonpool_xl_s13b_b90k'),\n ('ViT-L-14-336', 'openai'),\n ('ViT-H-14', 'laion2b_s32b_b79k'),\n ('ViT-g-14', 'laion2b_s12b_b42k'),\n ('ViT-g-14', 'laion2b_s34b_b88k'),\n ('ViT-bigG-14', 'laion2b_s39b_b160k'),\n ('roberta-ViT-B-32', 'laion2b_s12b_b32k'),\n ('xlm-roberta-base-ViT-B-32', 'laion5b_s13b_b90k'),\n ('xlm-roberta-large-ViT-H-14', 'frozen_laion5b_s13b_b90k'),\n ('convnext_base', 'laion400m_s13b_b51k'),\n ('convnext_base_w', 'laion2b_s13b_b82k'),\n ('convnext_base_w', 'laion2b_s13b_b82k_augreg'),\n ('convnext_base_w', 'laion_aesthetic_s13b_b82k'),\n ('convnext_base_w_320', 'laion_aesthetic_s13b_b82k'),\n ('convnext_base_w_320', 'laion_aesthetic_s13b_b82k_augreg'),\n ('convnext_large_d', 'laion2b_s26b_b102k_augreg'),\n ('convnext_large_d_320', 'laion2b_s29b_b131k_ft'),\n ('convnext_large_d_320', 'laion2b_s29b_b131k_ft_soup'),\n ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg'),\n ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg_rewind'),\n ('convnext_xxlarge', 'laion2b_s34b_b82k_augreg_soup'),\n ('coca_ViT-B-32', 'laion2b_s13b_b90k'),\n ('coca_ViT-B-32', 'mscoco_finetuned_laion2b_s13b_b90k'),\n ('coca_ViT-L-14', 'laion2b_s13b_b90k'),\n ('coca_ViT-L-14', 'mscoco_finetuned_laion2b_s13b_b90k'),\n ('EVA01-g-14', 'laion400m_s11b_b41k'),\n ('EVA01-g-14-plus', 'merged2b_s11b_b114k'),\n ('EVA02-B-16', 'merged2b_s8b_b131k'),\n ('EVA02-L-14', 'merged2b_s4b_b131k'),\n ('EVA02-L-14-336', 'merged2b_s6b_b61k'),\n ('EVA02-E-14', 'laion2b_s4b_b115k'),\n ('EVA02-E-14-plus', 'laion2b_s9b_b144k')]"},"metadata":{}}]},{"cell_type":"code","source":"import json\nimport requests\nimport torch\nfrom torch import nn\nimport numpy as np\nfrom zipfile import ZipFile\nfrom sklearn.decomposition import PCA\nfrom torchvision.transforms import InterpolationMode\nfrom torchvision.transforms.functional import resize, normalize\nimport open_clip\nfrom open_clip import create_model_and_transforms, tokenize\nimport pandas as pd \n\nfrom tqdm.notebook import tqdm, trange\n\n# import clip\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:02:29.872083Z","iopub.execute_input":"2023-07-29T17:02:29.872444Z","iopub.status.idle":"2023-07-29T17:02:30.518697Z","shell.execute_reply.started":"2023-07-29T17:02:29.872412Z","shell.execute_reply":"2023-07-29T17:02:30.517587Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"df_caption = pd.read_csv('/kaggle/input/multi-model-dataset/For validation/superAI/caption_id.csv')\ndf_caption.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:02:30.521758Z","iopub.execute_input":"2023-07-29T17:02:30.522142Z","iopub.status.idle":"2023-07-29T17:02:30.552503Z","shell.execute_reply.started":"2023-07-29T17:02:30.522101Z","shell.execute_reply":"2023-07-29T17:02:30.551156Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   caption_id                                            caption\n0          49  The man, with a straw hat and a white mask, is...\n1          85  Wearing a straw hat and a white face mask, the...\n2          86  With a straw hat and a white mask on, the man ...\n3          61  The man, donning a straw hat and a white face ...\n4          95  Sporting a straw hat and a white mask, the mal...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption_id</th>\n      <th>caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>49</td>\n      <td>The man, with a straw hat and a white mask, is...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>85</td>\n      <td>Wearing a straw hat and a white face mask, the...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>86</td>\n      <td>With a straw hat and a white mask on, the man ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>61</td>\n      <td>The man, donning a straw hat and a white face ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>95</td>\n      <td>Sporting a straw hat and a white mask, the mal...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_image = pd.read_csv('/kaggle/input/multi-model-dataset/For validation/superAI/img_id.csv')\ndf_image['file_path']=df_image['file_path'].apply(lambda x : '/kaggle/input/multi-model-dataset/For validation/superAI/imgs/'+x)\ndf_image['predict'] = [i for i in range(len(df_image))]\ndf_image.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:02:30.556012Z","iopub.execute_input":"2023-07-29T17:02:30.556703Z","iopub.status.idle":"2023-07-29T17:02:30.577121Z","shell.execute_reply.started":"2023-07-29T17:02:30.556665Z","shell.execute_reply":"2023-07-29T17:02:30.575888Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                           file_path  identity_id  predict\n0  /kaggle/input/multi-model-dataset/For validati...           38        0\n1  /kaggle/input/multi-model-dataset/For validati...           38        1\n2  /kaggle/input/multi-model-dataset/For validati...           38        2\n3  /kaggle/input/multi-model-dataset/For validati...           38        3\n4  /kaggle/input/multi-model-dataset/For validati...           39        4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_path</th>\n      <th>identity_id</th>\n      <th>predict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/multi-model-dataset/For validati...</td>\n      <td>38</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/multi-model-dataset/For validati...</td>\n      <td>38</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/multi-model-dataset/For validati...</td>\n      <td>38</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/multi-model-dataset/For validati...</td>\n      <td>38</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/multi-model-dataset/For validati...</td>\n      <td>39</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_sub = pd.read_csv('/kaggle/input/multi-model-dataset/For validation/superAI/sample_submission.csv')\ndf_sub.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:02:30.578559Z","iopub.execute_input":"2023-07-29T17:02:30.579142Z","iopub.status.idle":"2023-07-29T17:02:30.597219Z","shell.execute_reply.started":"2023-07-29T17:02:30.579107Z","shell.execute_reply":"2023-07-29T17:02:30.595984Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   caption_id  identity_id\n0          35         41.0\n1          69         38.0\n2          42         44.0\n3          17          NaN\n4          76          NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption_id</th>\n      <th>identity_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35</td>\n      <td>41.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>69</td>\n      <td>38.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>42</td>\n      <td>44.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>76</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_all = df_sub.merge(df_caption,how='left',on=['caption_id'])\ndf_all['predict'] = [i for i in range(len(df_all))]\ndf_all","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:02:30.599692Z","iopub.execute_input":"2023-07-29T17:02:30.600737Z","iopub.status.idle":"2023-07-29T17:02:30.629190Z","shell.execute_reply.started":"2023-07-29T17:02:30.600704Z","shell.execute_reply":"2023-07-29T17:02:30.628134Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"    caption_id  identity_id  \\\n0           35         41.0   \n1           69         38.0   \n2           42         44.0   \n3           17          NaN   \n4           76          NaN   \n..         ...          ...   \n95          29          NaN   \n96           8          NaN   \n97           9          NaN   \n98          64          NaN   \n99          43          NaN   \n\n                                              caption  predict  \n0   Sporting a white mask, the male individual is ...        0  \n1   The man, wearing a straw hat and a white mask,...        1  \n2   A powerful man is dressed in a red short-sleev...        2  \n3   A man is dressed in a red and white short-slee...        3  \n4   With a yellow safety helmet and a white mask o...        4  \n..                                                ...      ...  \n95  A towering man is dressed in a red short-sleev...       95  \n96  A strong man is seen wearing a red short-sleev...       96  \n97  Donning a white face mask, the male individual...       97  \n98  A boy in black shorts and short sleeves with a...       98  \n99  A tall man is wearing a red short-sleeved shir...       99  \n\n[100 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption_id</th>\n      <th>identity_id</th>\n      <th>caption</th>\n      <th>predict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35</td>\n      <td>41.0</td>\n      <td>Sporting a white mask, the male individual is ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>69</td>\n      <td>38.0</td>\n      <td>The man, wearing a straw hat and a white mask,...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>42</td>\n      <td>44.0</td>\n      <td>A powerful man is dressed in a red short-sleev...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17</td>\n      <td>NaN</td>\n      <td>A man is dressed in a red and white short-slee...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>76</td>\n      <td>NaN</td>\n      <td>With a yellow safety helmet and a white mask o...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>29</td>\n      <td>NaN</td>\n      <td>A towering man is dressed in a red short-sleev...</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>8</td>\n      <td>NaN</td>\n      <td>A strong man is seen wearing a red short-sleev...</td>\n      <td>96</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>Donning a white face mask, the male individual...</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>64</td>\n      <td>NaN</td>\n      <td>A boy in black shorts and short sleeves with a...</td>\n      <td>98</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>43</td>\n      <td>NaN</td>\n      <td>A tall man is wearing a red short-sleeved shir...</td>\n      <td>99</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load model and transforms\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel, _, preprocess = create_model_and_transforms('xlm-roberta-large-ViT-H-14', 'frozen_laion5b_s13b_b90k', device=device)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:02:30.630749Z","iopub.execute_input":"2023-07-29T17:02:30.631818Z","iopub.status.idle":"2023-07-29T17:05:08.743302Z","shell.execute_reply.started":"2023-07-29T17:02:30.631768Z","shell.execute_reply":"2023-07-29T17:05:08.741399Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd30213637cf417c8ad1c43d7d455fad"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"713e952e6fb74fcda75672fedf4c9443"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias']\n- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)ip_pytorch_model.bin:   0%|          | 0.00/4.77G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad52170a44e4493a80521c6722b7e55f"}},"metadata":{}}]},{"cell_type":"code","source":"model.eval()\ncontext_length = model.context_length\nvocab_size = model.vocab_size\n\nprint(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\nprint(\"Context length:\", context_length)\nprint(\"Vocab size:\", vocab_size)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:05:08.749211Z","iopub.execute_input":"2023-07-29T17:05:08.750180Z","iopub.status.idle":"2023-07-29T17:05:08.795310Z","shell.execute_reply.started":"2023-07-29T17:05:08.750150Z","shell.execute_reply":"2023-07-29T17:05:08.794364Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Model parameters: 1,193,014,785\nContext length: 514\nVocab size: 250002\n","output_type":"stream"}]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# model, _, preprocess = open_clip.create_model_and_transforms('ViT-H-14', pretrained='laion2b_s32b_b79k')\ntokenizer = open_clip.get_tokenizer('xlm-roberta-large-ViT-H-14')\n\nimage = [preprocess(Image.open(path)) for path in tqdm(df_image['file_path'])]\nimage_input = torch.tensor(np.stack(image)).cuda()\nlist_text=df_all['caption'].tolist()\n# image = preprocess(Image.open(df_image['file_path'][0])).unsqueeze(0).to(device)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:05:08.799698Z","iopub.execute_input":"2023-07-29T17:05:08.801168Z","iopub.status.idle":"2023-07-29T17:05:31.119994Z","shell.execute_reply.started":"2023-07-29T17:05:08.801133Z","shell.execute_reply":"2023-07-29T17:05:31.118967Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c8e97b8dd544ed8b2e630cdb63590a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42e67db48fcb430281dec20f2d11488a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e306485a033e48b3ae3b5dd4455e8d78"}},"metadata":{}}]},{"cell_type":"code","source":"image_input = torch.tensor(np.stack(image)).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:05:31.121610Z","iopub.execute_input":"2023-07-29T17:05:31.122077Z","iopub.status.idle":"2023-07-29T17:05:31.205867Z","shell.execute_reply.started":"2023-07-29T17:05:31.122012Z","shell.execute_reply":"2023-07-29T17:05:31.204861Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(list_text[0])\ntext = tokenizer(list_text[0]).to(device)\ntext","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:05:31.207472Z","iopub.execute_input":"2023-07-29T17:05:31.207860Z","iopub.status.idle":"2023-07-29T17:05:31.245842Z","shell.execute_reply.started":"2023-07-29T17:05:31.207826Z","shell.execute_reply":"2023-07-29T17:05:31.244944Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Sporting a white mask, the male individual is dressed in a yellow outerwear, black undershirt, black trousers, and black athletic shoes. He is holding a yellow plush toy in his hands.\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"tensor([[     0,   4706,    214,     10,  35011,   7021,      4,     70,  11280,\n          11651,     83,  40989,    297,     23,     10, 205811,   1810,     56,\n          87690,      4,  22556,   1379,  38184,      4,  22556,  36113,      7,\n           1314,      4,    136,  22556,     99,   7057,   9523, 148100,      5,\n           1529,     83, 104064,     10, 205811,   1001,    127,  72713,     23,\n           1919,  44540,      5,      2,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1,      1,      1,      1,      1,\n              1,      1,      1,      1,      1]], device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"text = tokenizer(list_text[0]).to(device)\n\nwith torch.no_grad(), torch.cuda.amp.autocast():\n    image_features = model.encode_image(image_input)\n    text_features = model.encode_text(text)\n    \n    image_features /= image_features.norm(dim=-1, keepdim=True)\n    text_features /= text_features.norm(dim=-1, keepdim=True)\n    similarity = text_features.cpu().numpy() @ image_features.cpu().numpy().T\n\nprint(\"Label probs:\", torch.from_numpy(similarity).argmax(dim=1).item())  \n","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:05:31.247439Z","iopub.execute_input":"2023-07-29T17:05:31.247811Z","iopub.status.idle":"2023-07-29T17:05:40.628699Z","shell.execute_reply.started":"2023-07-29T17:05:31.247778Z","shell.execute_reply":"2023-07-29T17:05:40.626670Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Label probs: 15\n","output_type":"stream"}]},{"cell_type":"code","source":"for i,column in tqdm(df_all.iterrows(),total=100) :\n    text = tokenizer(column['caption']).to(device)\n    with torch.no_grad():\n        image_features = model.encode_image(image_input)\n        text_features = model.encode_text(text)\n\n        image_features /= image_features.norm(dim=-1, keepdim=True)\n        text_features /= text_features.norm(dim=-1, keepdim=True)\n        similarity = text_features.cpu().numpy() @ image_features.cpu().numpy().T\n        \n    df_all.loc[i,'predict']=torch.from_numpy(similarity).argmax(dim=1).item()","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:05:40.630739Z","iopub.execute_input":"2023-07-29T17:05:40.631780Z","iopub.status.idle":"2023-07-29T17:15:18.315335Z","shell.execute_reply.started":"2023-07-29T17:05:40.631742Z","shell.execute_reply":"2023-07-29T17:15:18.309139Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ade0c2446db41abbee274eb09bc6171"}},"metadata":{}}]},{"cell_type":"code","source":"df_all","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:15:18.316749Z","iopub.execute_input":"2023-07-29T17:15:18.317117Z","iopub.status.idle":"2023-07-29T17:15:18.360076Z","shell.execute_reply.started":"2023-07-29T17:15:18.317083Z","shell.execute_reply":"2023-07-29T17:15:18.358962Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"    caption_id  identity_id  \\\n0           35         41.0   \n1           69         38.0   \n2           42         44.0   \n3           17          NaN   \n4           76          NaN   \n..         ...          ...   \n95          29          NaN   \n96           8          NaN   \n97           9          NaN   \n98          64          NaN   \n99          43          NaN   \n\n                                              caption  predict  \n0   Sporting a white mask, the male individual is ...       15  \n1   The man, wearing a straw hat and a white mask,...        3  \n2   A powerful man is dressed in a red short-sleev...       26  \n3   A man is dressed in a red and white short-slee...       32  \n4   With a yellow safety helmet and a white mask o...        6  \n..                                                ...      ...  \n95  A towering man is dressed in a red short-sleev...       23  \n96  A strong man is seen wearing a red short-sleev...       26  \n97  Donning a white face mask, the male individual...       15  \n98  A boy in black shorts and short sleeves with a...       40  \n99  A tall man is wearing a red short-sleeved shir...       17  \n\n[100 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption_id</th>\n      <th>identity_id</th>\n      <th>caption</th>\n      <th>predict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35</td>\n      <td>41.0</td>\n      <td>Sporting a white mask, the male individual is ...</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>69</td>\n      <td>38.0</td>\n      <td>The man, wearing a straw hat and a white mask,...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>42</td>\n      <td>44.0</td>\n      <td>A powerful man is dressed in a red short-sleev...</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17</td>\n      <td>NaN</td>\n      <td>A man is dressed in a red and white short-slee...</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>76</td>\n      <td>NaN</td>\n      <td>With a yellow safety helmet and a white mask o...</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>29</td>\n      <td>NaN</td>\n      <td>A towering man is dressed in a red short-sleev...</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>8</td>\n      <td>NaN</td>\n      <td>A strong man is seen wearing a red short-sleev...</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>Donning a white face mask, the male individual...</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>64</td>\n      <td>NaN</td>\n      <td>A boy in black shorts and short sleeves with a...</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>43</td>\n      <td>NaN</td>\n      <td>A tall man is wearing a red short-sleeved shir...</td>\n      <td>17</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_sub = df_all.merge(df_image,how='left',on=['predict'])\ndf_sub","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:15:18.361458Z","iopub.execute_input":"2023-07-29T17:15:18.362065Z","iopub.status.idle":"2023-07-29T17:15:18.404551Z","shell.execute_reply.started":"2023-07-29T17:15:18.362028Z","shell.execute_reply":"2023-07-29T17:15:18.403496Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"    caption_id  identity_id_x  \\\n0           35           41.0   \n1           69           38.0   \n2           42           44.0   \n3           17            NaN   \n4           76            NaN   \n..         ...            ...   \n95          29            NaN   \n96           8            NaN   \n97           9            NaN   \n98          64            NaN   \n99          43            NaN   \n\n                                              caption  predict  \\\n0   Sporting a white mask, the male individual is ...       15   \n1   The man, wearing a straw hat and a white mask,...        3   \n2   A powerful man is dressed in a red short-sleev...       26   \n3   A man is dressed in a red and white short-slee...       32   \n4   With a yellow safety helmet and a white mask o...        6   \n..                                                ...      ...   \n95  A towering man is dressed in a red short-sleev...       23   \n96  A strong man is seen wearing a red short-sleev...       26   \n97  Donning a white face mask, the male individual...       15   \n98  A boy in black shorts and short sleeves with a...       40   \n99  A tall man is wearing a red short-sleeved shir...       17   \n\n                                            file_path  identity_id_y  \n0   /kaggle/input/multi-model-dataset/For validati...             41  \n1   /kaggle/input/multi-model-dataset/For validati...             38  \n2   /kaggle/input/multi-model-dataset/For validati...             44  \n3   /kaggle/input/multi-model-dataset/For validati...             46  \n4   /kaggle/input/multi-model-dataset/For validati...             39  \n..                                                ...            ...  \n95  /kaggle/input/multi-model-dataset/For validati...             43  \n96  /kaggle/input/multi-model-dataset/For validati...             44  \n97  /kaggle/input/multi-model-dataset/For validati...             41  \n98  /kaggle/input/multi-model-dataset/For validati...             48  \n99  /kaggle/input/multi-model-dataset/For validati...             42  \n\n[100 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption_id</th>\n      <th>identity_id_x</th>\n      <th>caption</th>\n      <th>predict</th>\n      <th>file_path</th>\n      <th>identity_id_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35</td>\n      <td>41.0</td>\n      <td>Sporting a white mask, the male individual is ...</td>\n      <td>15</td>\n      <td>/kaggle/input/multi-model-dataset/For validati...</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>69</td>\n      <td>38.0</td>\n      <td>The man, wearing a straw hat and a white mask,...</td>\n      <td>3</td>\n      <td>/kaggle/input/multi-model-dataset/For validati...</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>42</td>\n      <td>44.0</td>\n      <td>A powerful man is dressed in a red short-sleev...</td>\n      <td>26</td>\n      <td>/kaggle/input/multi-model-dataset/For validati...</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17</td>\n      <td>NaN</td>\n      <td>A man is dressed in a red and white short-slee...</td>\n      <td>32</td>\n      <td>/kaggle/input/multi-model-dataset/For validati...</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>76</td>\n      <td>NaN</td>\n      <td>With a yellow safety helmet and a white mask o...</td>\n      <td>6</td>\n      <td>/kaggle/input/multi-model-dataset/For validati...</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>29</td>\n      <td>NaN</td>\n      <td>A towering man is dressed in a red short-sleev...</td>\n      <td>23</td>\n      <td>/kaggle/input/multi-model-dataset/For validati...</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>8</td>\n      <td>NaN</td>\n      <td>A strong man is seen wearing a red short-sleev...</td>\n      <td>26</td>\n      <td>/kaggle/input/multi-model-dataset/For validati...</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>Donning a white face mask, the male individual...</td>\n      <td>15</td>\n      <td>/kaggle/input/multi-model-dataset/For validati...</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>64</td>\n      <td>NaN</td>\n      <td>A boy in black shorts and short sleeves with a...</td>\n      <td>40</td>\n      <td>/kaggle/input/multi-model-dataset/For validati...</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>43</td>\n      <td>NaN</td>\n      <td>A tall man is wearing a red short-sleeved shir...</td>\n      <td>17</td>\n      <td>/kaggle/input/multi-model-dataset/For validati...</td>\n      <td>42</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_sub['identity_id_y'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:16:36.203185Z","iopub.execute_input":"2023-07-29T17:16:36.203574Z","iopub.status.idle":"2023-07-29T17:16:36.212615Z","shell.execute_reply.started":"2023-07-29T17:16:36.203545Z","shell.execute_reply":"2023-07-29T17:16:36.211554Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"46    11\n41     8\n38     8\n44     8\n39     8\n40     8\n45     8\n47     8\n43     8\n42     7\n48     6\n49     5\n51     3\n55     2\n62     1\n50     1\nName: identity_id_y, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df_submission = pd.read_csv('/kaggle/input/multi-model-dataset/For validation/superAI/sample_submission.csv')\ndf_submission.loc[3:,'identity_id']=df_sub['identity_id_y'][3:]\ndf_submission","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:16:36.424751Z","iopub.execute_input":"2023-07-29T17:16:36.425447Z","iopub.status.idle":"2023-07-29T17:16:36.448377Z","shell.execute_reply.started":"2023-07-29T17:16:36.425412Z","shell.execute_reply":"2023-07-29T17:16:36.447234Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"    caption_id  identity_id\n0           35         41.0\n1           69         38.0\n2           42         44.0\n3           17         46.0\n4           76         39.0\n..         ...          ...\n95          29         43.0\n96           8         44.0\n97           9         41.0\n98          64         48.0\n99          43         42.0\n\n[100 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption_id</th>\n      <th>identity_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35</td>\n      <td>41.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>69</td>\n      <td>38.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>42</td>\n      <td>44.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17</td>\n      <td>46.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>76</td>\n      <td>39.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>29</td>\n      <td>43.0</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>8</td>\n      <td>44.0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>9</td>\n      <td>41.0</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>64</td>\n      <td>48.0</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>43</td>\n      <td>42.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_submission.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:16:36.603675Z","iopub.execute_input":"2023-07-29T17:16:36.604053Z","iopub.status.idle":"2023-07-29T17:16:36.611893Z","shell.execute_reply.started":"2023-07-29T17:16:36.604015Z","shell.execute_reply":"2023-07-29T17:16:36.610712Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"df_submission['identity_id'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:16:36.785339Z","iopub.execute_input":"2023-07-29T17:16:36.785706Z","iopub.status.idle":"2023-07-29T17:16:36.795518Z","shell.execute_reply.started":"2023-07-29T17:16:36.785678Z","shell.execute_reply":"2023-07-29T17:16:36.794363Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"46.0    11\n41.0     8\n38.0     8\n44.0     8\n39.0     8\n40.0     8\n45.0     8\n47.0     8\n43.0     8\n42.0     7\n48.0     6\n49.0     5\n51.0     3\n55.0     2\n62.0     1\n50.0     1\nName: identity_id, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}